# This module takes bed file as input and split it into chunks according to the
# parameter number_of_chunk in configfile.
# Besides, it takes the split regions and prepare the input files for
# downstream analysis

def all_chunks(name):
    out = []
    for i in range(config[name]['number_of_chunk']):
        out.append('chunks/{bed}/chunk_{i}.input.gz'.format(i=i, bed=name))
    return out

rule all:
    input:
        all_chunks(config['name'])

rule split:
    input:
        lambda wildcards: config[wildcards.bed]['path']
    params:
        nchunk = lambda wildcards: config[wildcards.bed]['number_of_chunk'],
        outdir = lambda wildcards: 'chunks/{wildcards.bed}/'
    output:
        lambda wildcards: [ 'chunks/{{bed}}/chunk_{i}.raw'.format(i=i) for i in range(config[wildcards.bed]['number_of_chunk']) ]
    shell:
        'python scripts/split.py --input {input[0]} --nchunk {params.nchunk} --outdir {params.outdir}'

rule prepare_input_getseq:
    input:
        'chunks/{bed}/chunk_{i}.raw'
    params:
        genome = config['genome_assembly']['fasta']
    output:
        temp('chunks/{{bed}}/chunk_{i}.tab.gz')
    shell:
        'bedtools getfasta -fi {params.genome} -bed {input[0]} -name -tab | gzip > {output[0]}'

rule prepare_input_geninput:
    input:
        seq = 'chunks/{bed}/chunk_{i}.tab.gz'
    params:
        script = lambda wildcards: config[wildcards.bed]['prepare_input_script']
    log:
        'log/{bed}_chunk_{i}.log'
    output:
        'chunks/{{bed}}/chunk_{i}.input.gz'
    shell:
        'python scripts/{params.script} --input_seq {input.seq} --log {log} | gzip > {output[0]}'
