# This module takes bed file as input and split it into chunks according to the
# parameter number_of_chunk in configfile.
# Besides, it takes the split regions and prepare the input files for
# downstream analysis

def all_chunks(name):
    out = []
    for i in range(config[name]['number_of_chunk']):
        out.append('chunks/{bed}/chunk_{i}.input.gz'.format(i=i, bed=name))
    return out

rule all:
    input:
        all_chunks(config['name'])

rule merge_overlap:
    input:
        lambda wildcards: config[wildcards.bed]['path']
    output:
        'merged/{bed}.merged.bed'
    shell:
        'bedtools merge -i {input[0]} -c 4,5 -o collpase,collpase > {output[0]}'

rule split:
    input:
        'merged/{bed}.merged.bed'
    params:
        nchunk = lambda wildcards: config[wildcards.bed]['number_of_chunk'],
        outdir = lambda wildcards: 'chunks/{bed}/'
    output:
        [ 'chunks/{{bed}}/chunk_{i}.raw'.format(i=i) for i in range(config[config['name']]['number_of_chunk']) ]
    shell:
        'python scripts/split.py --input {input[0]} --nchunk {params.nchunk} --outdir {params.outdir}'

rule prepare_input_getseq:
    input:
        'chunks/{bed}/chunk_{i}.raw'
    params:
        genome = config['genome_assembly']['fasta']
    output:
        temp('chunks/{bed}/chunk_{i}.tab')
    shell:
        'bedtools getfasta -fi {params.genome} -bed {input[0]} -fo {output[0]} -tab'

rule prepare_input_compress:
    input:
        'chunks/{bed}/chunk_{i}.tab'
    output:
        temp('chunks/{bed}/chunk_{i}.tab.gz')
    shell:
        'gzip {input[0]}'

rule prepare_input_geninput:
    input:
        seq = 'chunks/{bed}/chunk_{i}.tab.gz'
    params:
        script = lambda wildcards: config[wildcards.bed]['prepare_input_script']
    log:
        'log/{bed}_chunk_{i}.log'
    output:
        good = 'chunks/{bed}/chunk_{i}.input.gz',
        bad = 'chunks/{bed}/chunk_{i}.bad.input'
    shell:
        'python scripts/{params.script} --input_seq {input.seq} --log {log} --exclude {output.bad} | gzip > {output.good}'
